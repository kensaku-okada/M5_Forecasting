{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.kaggle.com/ejunichi/m5-simple-fe from https://www.kaggle.com/ejunichi/m5-three-shades-of-dark-darker-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import gc\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import psutil\n",
    "import warnings\n",
    "\n",
    "# custom import\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constant variables for helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CORES: 16\n"
     ]
    }
   ],
   "source": [
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "print(f\"N_CORES: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function nicely diplaying a head of Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "def display(*dfs, head=True):\n",
    "    for df in dfs:\n",
    "        IPython.display.display(df.head() if head else df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function fixing random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Sets seed to make all processes deterministic     # type: int\n",
    "    \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function processing df in multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_df_in_multiprocess(func, t_split):\n",
    "    \"\"\"Process ds in Multiprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"メモリ使用量を確認するためのシンプルな「メモリプロファイラ」\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    \"\"\"\n",
    "    dtypesを失わないための連結による結合\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  constant variables for data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _DATA_DIR = os.path.sep.join([\"data\", \"M5_Three_shades_of_Dark_Darker_magic\", \"sample\"])\n",
    "# _DATA_DIR = os.path.sep.join([\"data\", \"M5_Three_shades_of_Dark_Darker_magic\"])\n",
    "_DATA_DIR = os.path.sep.join([\"data\", \"M5_Three_shades_of_Dark_Darker_magic\"])\n",
    "\n",
    "_CALENDAR_CSV_FILE = \"calendar.csv\"\n",
    "_SAMPLE_SUBMISSION_CSV_FILE = \"sample_submission.csv\"\n",
    "# _SALES_TRAIN_VALIDATION_CSV_FILE = \"sales_train_validation.csv\"\n",
    "_SALES_TRAIN_EVALUATION_CSV_FILE = \"sales_train_evaluation.csv\"\n",
    "_SELL_PRICES_CSV_FILE = \"sell_prices.csv\"\n",
    "\n",
    "# S3より取得済み。\n",
    "_IS_RUN_ON_SAGEMAKER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downlaod data (only on sagemaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if _IS_RUN_ON_SAGEMAKER:\n",
    "    import sagemaker\n",
    "\n",
    "    # print(sagemaker.s3.parse_s3_url('s3://sagemaker-m5-forecasting-okada/accuracy/original/calendar.csv'))\n",
    "    parent_dir = pathlib.Path(os.path.abspath(os.curdir)).parent.parent\n",
    "    local_path = os.path.sep.join([str(parent_dir), _DATA_DIR])\n",
    "    print(local_path)\n",
    "\n",
    "    def import_one_object_from_s3(s3_uri, local_path):\n",
    "\n",
    "        sagemaker.s3.S3Downloader.download(\n",
    "            s3_uri=s3_uri,\n",
    "            local_path=local_path\n",
    "        )\n",
    "        !ls $local_path\n",
    "\n",
    "    calendar_data_s3_uri = 's3://sagemaker-m5-forecasting-okada/accuracy/original/calendar.csv'\n",
    "    sales_train_evaluation_data_s3_uri = 's3://sagemaker-m5-forecasting-okada/accuracy/original/sales_train_evaluation.csv'\n",
    "    sales_train_validation_data_s3_uri = 's3://sagemaker-m5-forecasting-okada/accuracy/original/sales_train_validation.csv'\n",
    "    sample_submission_data_s3_uri = 's3://sagemaker-m5-forecasting-okada/accuracy/original/sample_submission.csv'\n",
    "    sell_prices_data_s3_uri = 's3://sagemaker-m5-forecasting-okada/accuracy/original/sell_prices.csv'\n",
    "\n",
    "    s3_uris = [\n",
    "        calendar_data_s3_uri,\n",
    "        sales_train_evaluation_data_s3_uri,\n",
    "        sales_train_validation_data_s3_uri,\n",
    "        sample_submission_data_s3_uri,\n",
    "        sell_prices_data_s3_uri\n",
    "    ]\n",
    "\n",
    "    for s3_uri in s3_uris:\n",
    "        import_one_object_from_s3(s3_uri, local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    reduce the memory usage of the given dataframe.\n",
    "    https://qiita.com/hiroyuki_kageyama/items/02865616811022f79754\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe\n",
    "        verbose: \n",
    "        \n",
    "    Returns:\n",
    "        df, whose memory usage is reduced.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns: #columns毎に処理\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def read_csv_data(directory, file_name):\n",
    "    print('Reading files...')\n",
    "    df = pd.read_csv(os.path.sep.join([str(directory), _DATA_DIR, file_name]))\n",
    "    df = reduce_mem_usage(df)\n",
    "    print('{} has {} rows and {} columns'.format(file_name, df.shape[0], df.shape[1]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_dir: /home/ec2-user/SageMaker\n",
      "Reading files...\n",
      "Mem. usage decreased to 96.13 Mb (78.8% reduction)\n",
      "sales_train_evaluation.csv has 30490 rows and 1947 columns\n"
     ]
    }
   ],
   "source": [
    "parent_dir = pathlib.Path(os.path.abspath(os.curdir)).parent.parent\n",
    "print(f\"parent_dir: {parent_dir}\")\n",
    "\n",
    "df_sales_train_evaluation = read_csv_data(parent_dir, _SALES_TRAIN_EVALUATION_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "sell_prices.csv has 6841121 rows and 4 columns\n"
     ]
    }
   ],
   "source": [
    "df_sell_prices = read_csv_data(parent_dir, _SELL_PRICES_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "calendar.csv has 1969 rows and 14 columns\n"
     ]
    }
   ],
   "source": [
    "df_calendar = read_csv_data(parent_dir, _CALENDAR_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Mem. usage decreased to  2.09 Mb (84.5% reduction)\n",
      "sample_submission.csv has 60980 rows and 29 columns\n"
     ]
    }
   ],
   "source": [
    "df_sample_submission = read_csv_data(parent_dir, _SAMPLE_SUBMISSION_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sales_train_evaluation:                               id        item_id    dept_id   cat_id store_id  \\\n",
      "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
      "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
      "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
      "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
      "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
      "\n",
      "  state_id  d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9  d_10  d_11  d_12  \\\n",
      "0       CA    0    0    0    0    0    0    0    0    0     0     0     0   \n",
      "1       CA    0    0    0    0    0    0    0    0    0     0     0     0   \n",
      "2       CA    0    0    0    0    0    0    0    0    0     0     0     0   \n",
      "3       CA    0    0    0    0    0    0    0    0    0     0     0     0   \n",
      "4       CA    0    0    0    0    0    0    0    0    0     0     0     0   \n",
      "\n",
      "   d_13  d_14  d_15  d_16  d_17  d_18  d_19  d_20  d_21  d_22  d_23  d_24  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_25  d_26  d_27  d_28  d_29  d_30  d_31  d_32  d_33  d_34  d_35  d_36  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_37  d_38  d_39  d_40  d_41  d_42  d_43  d_44  d_45  d_46  d_47  d_48  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     2     0     0     0     2     0     1     0     0     0     0     0   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_49  d_50  d_51  d_52  d_53  d_54  d_55  d_56  d_57  d_58  d_59  d_60  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     0     2     0     1     0     0     1     1     1     0     2     3   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_61  d_62  d_63  d_64  d_65  d_66  d_67  d_68  d_69  d_70  d_71  d_72  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     1     0     0     0     0     0     1     0     0     1     1     0   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_73  d_74  d_75  d_76  d_77  d_78  d_79  d_80  d_81  d_82  d_83  d_84  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     0     1     0     0     1     2     3     0     2     0     0     2   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_85  d_86  d_87  d_88  d_89  d_90  d_91  d_92  d_93  d_94  d_95  d_96  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "3     2     0     0     2     1     2     1     1     1     2     0     0   \n",
      "4     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   d_97  d_98  d_99  d_100  d_101  d_102  d_103  d_104  d_105  d_106  d_107  \\\n",
      "0     0     0     0      0      0      0      0      0      0      0      0   \n",
      "1     0     0     0      0      0      0      0      0      0      0      0   \n",
      "2     0     0     0      0      0      0      0      0      0      0      0   \n",
      "3     1     0     1      3      1      0      0      0      0      3      5   \n",
      "4     0     0     0      0      0      0      0      0      0      0      0   \n",
      "\n",
      "   d_108  d_109  d_110  d_111  d_112  d_113  d_114  d_115  d_116  d_117  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      0      0      0      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      2      2      1      1      1      1      1      1      0      0   \n",
      "4      0      0      0      0      0      8      6      0      3      2   \n",
      "\n",
      "   d_118  d_119  d_120  d_121  d_122  d_123  d_124  d_125  d_126  d_127  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      0      0      0      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      2      1      1      1      2      0      0      0      2      5   \n",
      "4      3      5      3      1      0      0      1      0      2      2   \n",
      "\n",
      "   d_128  d_129  d_130  d_131  d_132  d_133  d_134  d_135  d_136  d_137  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      0      0      0      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      6      0      0      0      0      0      0      0      0      0   \n",
      "4      4      0      0      3      1      1      1      2      2      0   \n",
      "\n",
      "   d_138  d_139  d_140  d_141  d_142  d_143  d_144  d_145  d_146  d_147  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      0      1      0      0      1   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      0      0      2      1      2      0      1      0      2      0   \n",
      "4      0      0      0      0      0      3      7      1      1      0   \n",
      "\n",
      "   d_148  d_149  d_150  d_151  d_152  d_153  d_154  d_155  d_156  d_157  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      1      1      0      1      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      0      5      1      0      0      1      3      1      3      5   \n",
      "4      0      0      0      0      0      0      0      1      0      0   \n",
      "\n",
      "   d_158  d_159  d_160  d_161  d_162  d_163  d_164  d_165  d_166  d_167  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      1      0      0      0      1      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      1      3      0      3      4      4      0      0      1      3   \n",
      "4      0      0      0      0      0      0      0      1      0      0   \n",
      "\n",
      "   d_168  d_169  d_170  d_171  d_172  d_173  d_174  d_175  d_176  d_177  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      0      0      0      1      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      1      4      0      0      2      0      2      0      1      4   \n",
      "4      0      0      0      0      0      0      0      0      0      0   \n",
      "\n",
      "   d_178  d_179  d_180  d_181  d_182  d_183  d_184  d_185  d_186  d_187  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      0      0      0      0      0      0      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      2      1      0      2      1      3      6      1      1      2   \n",
      "4      0      0      0      0      0      0      3      3      2      0   \n",
      "\n",
      "   d_188  d_189  d_190  d_191  d_192  d_193  d_194  d_195  d_196  d_197  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      1      0      0      1      0      0      0      0      0      1   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      1      2      3      1      2      0      0      0      3      4   \n",
      "4      0      0      0      0      0      0      2      0      6      2   \n",
      "\n",
      "   d_198  d_199  d_200  d_201  d_202  d_203  d_204  d_205  d_206  d_207  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      1      1      1      0      1      0      0      0      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      5      1      0      0      1      0      1      4      6      3   \n",
      "4      4      2      0      0      3      2      4      1      0      0   \n",
      "\n",
      "   d_208  d_209  d_210  d_211  d_212  d_213  d_214  d_215  d_216  d_217  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      1      0      0      1      0      0      0      1      0      1   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      1      1      0      1      4      5      1      1      4      0   \n",
      "4      0      0      1      1      1      2      0      0      0      0   \n",
      "\n",
      "   d_218  d_219  d_220  d_221  d_222  d_223  d_224  d_225  d_226  d_227  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      1      0      1      0      0      0      0      0      0      1   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      0      0      1      2      2      1      1      6      2      4   \n",
      "4      0      0      0      0      2      6      7      9      4      7   \n",
      "\n",
      "   d_228  d_229  d_230  d_231  d_232  d_233  d_234  d_235  d_236  d_237  \\\n",
      "0      0      0      0      0      0      0      0      0      0      0   \n",
      "1      0      0      1      0      0      0      0      0      0      0   \n",
      "2      0      0      0      0      0      0      0      0      0      0   \n",
      "3      4      0      0      0      2      2      0      1      1      3   \n",
      "4      6      3      4      2      0      1      5      2      2      0   \n",
      "\n",
      "   d_238  d_239  d_240  d_241  d_242  d_243  d_244  ...  d_1692  d_1693  \\\n",
      "0      0      0      0      0      0      0      0  ...       2       0   \n",
      "1      0      0      1      0      0      0      1  ...       1       0   \n",
      "2      0      0      0      0      0      0      0  ...       0       1   \n",
      "3      1      2      4      2      1      3      2  ...       0       3   \n",
      "4      0      0      0      0      0      1      3  ...       0       1   \n",
      "\n",
      "   d_1694  d_1695  d_1696  d_1697  d_1698  d_1699  d_1700  d_1701  d_1702  \\\n",
      "0       0       0       0       0       0       0       1       0       1   \n",
      "1       0       1       1       0       0       0       0       0       0   \n",
      "2       0       1       0       0       0       0       2       0       1   \n",
      "3       3       1       7       3       1       0       0       1       0   \n",
      "4       0       0       3       1       2       2       0       1       1   \n",
      "\n",
      "   d_1703  d_1704  d_1705  d_1706  d_1707  d_1708  d_1709  d_1710  d_1711  \\\n",
      "0       0       1       0       3       1       1       0       1       1   \n",
      "1       0       2       1       0       0       1       0       0       0   \n",
      "2       0       1       0       1       1       0       1       0       1   \n",
      "3       1       1       0       0       2       1       4       4       3   \n",
      "4       0       4       0       0       4       0       2       2       2   \n",
      "\n",
      "   d_1712  d_1713  d_1714  d_1715  d_1716  d_1717  d_1718  d_1719  d_1720  \\\n",
      "0       2       0       0       0       0       1       1       0       0   \n",
      "1       0       0       0       0       0       3       0       0       0   \n",
      "2       0       0       0       1       2       0       0       0       1   \n",
      "3       0       2       0       0       1       3       3       0       2   \n",
      "4       1       2       1       1       1       4       0       2       1   \n",
      "\n",
      "   d_1721  d_1722  d_1723  d_1724  d_1725  d_1726  d_1727  d_1728  d_1729  \\\n",
      "0       0       0       3       0       1       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       1       0   \n",
      "2       0       1       1       1       1       0       0       0       0   \n",
      "3       1       2       4       7       0       2       1       0       5   \n",
      "4       2       0       0       1       0       1       1       2       2   \n",
      "\n",
      "   d_1730  d_1731  d_1732  d_1733  d_1734  d_1735  d_1736  d_1737  d_1738  \\\n",
      "0       1       1       1       0       1       0       2       0       0   \n",
      "1       2       1       0       0       0       1       1       0       0   \n",
      "2       0       0       2       0       1       0       0       2       0   \n",
      "3       5       2       2       4       1       0       0       3       1   \n",
      "4       3       1       0       2       3       0       1       1       4   \n",
      "\n",
      "   d_1739  d_1740  d_1741  d_1742  d_1743  d_1744  d_1745  d_1746  d_1747  \\\n",
      "0       0       0       2       0       0       0       0       1       1   \n",
      "1       0       0       1       1       0       1       0       1       1   \n",
      "2       0       0       1       0       0       1       0       0       2   \n",
      "3       0       0       0       3       1       3       3       0       0   \n",
      "4       0       3       2       1       2       1       2       2       1   \n",
      "\n",
      "   d_1748  d_1749  d_1750  d_1751  d_1752  d_1753  d_1754  d_1755  d_1756  \\\n",
      "0       2       0       0       0       0       2       0       0       1   \n",
      "1       0       0       0       0       0       1       0       1       1   \n",
      "2       0       0       0       0       0       0       0       0       2   \n",
      "3       4       1       1       1       1       3       3       1       0   \n",
      "4       2       0       1       1       2       0       2       0       0   \n",
      "\n",
      "   d_1757  d_1758  d_1759  d_1760  d_1761  d_1762  d_1763  d_1764  d_1765  \\\n",
      "0       1       1       1       0       0       0       0       0       1   \n",
      "1       0       3       0       0       0       0       0       0       0   \n",
      "2       0       2       3       0       1       3       1       2       2   \n",
      "3       3       0       1       3       3       3       2       2       2   \n",
      "4       0       4       2       1       2       0       0       0       0   \n",
      "\n",
      "   d_1766  d_1767  d_1768  d_1769  d_1770  d_1771  d_1772  d_1773  d_1774  \\\n",
      "0       2       2       0       1       0       0       0       0       1   \n",
      "1       1       0       0       0       0       0       2       1       0   \n",
      "2       3       0       1       1       0       0       0       0       2   \n",
      "3       4       3       0       5       1       3       3       2       0   \n",
      "4       0       2       1       0       0       1       2       0       1   \n",
      "\n",
      "   d_1775  d_1776  d_1777  d_1778  d_1779  d_1780  d_1781  d_1782  d_1783  \\\n",
      "0       2       1       0       0       0       0       0       1       0   \n",
      "1       0       1       1       0       2       0       1       0       2   \n",
      "2       3       1       1       4       3       2       1       2       2   \n",
      "3       0       1       1       0       2       2       2       3       2   \n",
      "4       2       1       2       1       2       3       3       0       3   \n",
      "\n",
      "   d_1784  d_1785  d_1786  d_1787  d_1788  d_1789  d_1790  d_1791  d_1792  \\\n",
      "0       3       0       1       2       1       0       3       0       0   \n",
      "1       1       1       5       0       1       0       3       5       0   \n",
      "2       0       1       5       2       0       1       2       3       0   \n",
      "3       1       2       0       5       0       1       0       0       0   \n",
      "4       1       5       3       2       1       2       3       4       0   \n",
      "\n",
      "   d_1793  d_1794  d_1795  d_1796  d_1797  d_1798  d_1799  d_1800  d_1801  \\\n",
      "0       0       1       0       2       2       1       0       0       1   \n",
      "1       0       1       0       0       0       0       0       0       0   \n",
      "2       1       2       1       3       0       1       1       1       1   \n",
      "3       3       4       0       0       1       5       3       2       2   \n",
      "4       0       1       0       0       1       0       0       1       0   \n",
      "\n",
      "   d_1802  d_1803  d_1804  d_1805  d_1806  d_1807  d_1808  d_1809  d_1810  \\\n",
      "0       2       0       1       0       1       4       0       0       5   \n",
      "1       0       0       0       0       0       1       0       0       0   \n",
      "2       0       0       0       0       0       0       0       1       0   \n",
      "3       0       1       1       0       2       1       0       2       4   \n",
      "4       0       0       0       2       0       0       3       0       0   \n",
      "\n",
      "   d_1811  d_1812  d_1813  d_1814  d_1815  d_1816  d_1817  d_1818  d_1819  \\\n",
      "0       0       0       0       0       0       0       2       1       2   \n",
      "1       0       0       1       0       0       1       0       0       0   \n",
      "2       1       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       3       2       4       3       1       2   \n",
      "4       1       2       2       0       1       0       0       0       1   \n",
      "\n",
      "   d_1820  d_1821  d_1822  d_1823  d_1824  d_1825  d_1826  d_1827  d_1828  \\\n",
      "0       1       0       0       0       1       1       1       0       0   \n",
      "1       0       0       0       0       0       0       1       0       0   \n",
      "2       0       0       0       0       0       0       0       0       1   \n",
      "3       3       0       8       2       1       2       2       5       2   \n",
      "4       0       0       3       0       0       1       1       0       3   \n",
      "\n",
      "   d_1829  d_1830  d_1831  d_1832  d_1833  d_1834  d_1835  d_1836  d_1837  \\\n",
      "0       1       1       1       1       1       0       0       0       2   \n",
      "1       0       1       0       0       0       0       0       0       1   \n",
      "2       0       0       0       0       0       0       0       1       0   \n",
      "3       6       1       0       3       5       1       1       6       4   \n",
      "4       1       0       4       1       2       0       0       0       1   \n",
      "\n",
      "   d_1838  d_1839  d_1840  d_1841  d_1842  d_1843  d_1844  d_1845  d_1846  \\\n",
      "0       2       0       0       1       4       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       1       0   \n",
      "2       1       1       1       1       1       0       0       0       1   \n",
      "3       3       2       2       3       2       1       0       0       0   \n",
      "4       1       2       0       0       5       2       2       2       1   \n",
      "\n",
      "   d_1847  d_1848  d_1849  d_1850  d_1851  d_1852  d_1853  d_1854  d_1855  \\\n",
      "0       1       1       2       0       4       0       1       0       1   \n",
      "1       0       0       1       0       0       0       0       1       0   \n",
      "2       0       1       0       1       0       0       0       0       0   \n",
      "3       2       0       5       4       2       1       1       2       3   \n",
      "4       0       0       0       3       0       0       0       3       1   \n",
      "\n",
      "   d_1856  d_1857  d_1858  d_1859  d_1860  d_1861  d_1862  d_1863  d_1864  \\\n",
      "0       4       2       0       2       0       1       1       0       1   \n",
      "1       0       0       0       0       0       1       0       0       1   \n",
      "2       0       0       0       0       0       0       0       6       1   \n",
      "3       0       6       0       0       0       1       0       1       5   \n",
      "4       1       1       1       2       1       0       0       1       0   \n",
      "\n",
      "   d_1865  d_1866  d_1867  d_1868  d_1869  d_1870  d_1871  d_1872  d_1873  \\\n",
      "0       0       0       1       1       3       0       0       0       1   \n",
      "1       1       0       0       1       0       1       0       0       0   \n",
      "2       1       2       0       0       0       1       1       0       0   \n",
      "3       3       1       0       0       0       1       2       3       0   \n",
      "4       2       1       1       0       3       1       1       2       1   \n",
      "\n",
      "   d_1874  d_1875  d_1876  d_1877  d_1878  d_1879  d_1880  d_1881  d_1882  \\\n",
      "0       1       1       3       1       3       1       2       2       0   \n",
      "1       0       0       0       0       0       0       0       0       1   \n",
      "2       0       0       1       0       0       0       0       0       0   \n",
      "3       1       3       4       2       1       4       1       3       5   \n",
      "4       1       0       3       2       2       2       3       1       0   \n",
      "\n",
      "   d_1883  d_1884  d_1885  d_1886  d_1887  d_1888  d_1889  d_1890  d_1891  \\\n",
      "0       1       1       1       1       0       0       0       0       0   \n",
      "1       1       1       1       1       0       0       0       0       0   \n",
      "2       1       1       0       0       0       0       0       0       0   \n",
      "3       0       6       6       0       0       0       0       3       1   \n",
      "4       0       0       0       1       0       4       4       0       1   \n",
      "\n",
      "   d_1892  d_1893  d_1894  d_1895  d_1896  d_1897  d_1898  d_1899  d_1900  \\\n",
      "0       1       0       4       2       3       0       1       2       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       1       0       0       0       1       0       0       0       0   \n",
      "3       2       1       3       1       0       2       5       4       2   \n",
      "4       4       0       1       0       1       0       1       1       2   \n",
      "\n",
      "   d_1901  d_1902  d_1903  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  \\\n",
      "0       0       0       1       1       3       0       1       1       1   \n",
      "1       0       0       0       0       0       0       0       0       1   \n",
      "2       0       1       2       2       1       2       1       1       1   \n",
      "3       0       3       0       1       0       5       4       1       0   \n",
      "4       0       1       1       2       1       1       0       1       1   \n",
      "\n",
      "   d_1910  d_1911  d_1912  d_1913  d_1914  d_1915  d_1916  d_1917  d_1918  \\\n",
      "0       3       0       1       1       0       0       0       2       0   \n",
      "1       0       0       0       0       0       1       0       0       0   \n",
      "2       0       1       1       1       0       0       1       1       0   \n",
      "3       1       3       7       2       0       0       1       2       4   \n",
      "4       2       2       2       4       1       0       2       3       1   \n",
      "\n",
      "   d_1919  d_1920  d_1921  d_1922  d_1923  d_1924  d_1925  d_1926  d_1927  \\\n",
      "0       3       5       0       0       1       1       0       2       1   \n",
      "1       0       0       0       0       1       0       0       0       0   \n",
      "2       2       1       0       0       0       0       2       1       3   \n",
      "3       1       6       4       0       0       0       2       2       4   \n",
      "4       0       3       2       3       1       1       3       2       3   \n",
      "\n",
      "   d_1928  d_1929  d_1930  d_1931  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
      "0       2       2       1       0       2       4       0       0       0   \n",
      "1       0       0       0       0       0       1       2       1       1   \n",
      "2       0       0       1       0       1       0       2       0       0   \n",
      "3       2       1       1       1       1       1       0       4       0   \n",
      "4       2       2       2       2       0       0       0       2       1   \n",
      "\n",
      "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
      "0       0       3       3       0       1  \n",
      "1       0       0       0       0       0  \n",
      "2       0       2       3       0       1  \n",
      "3       1       3       0       2       6  \n",
      "4       0       0       2       1       0  \n",
      "\n",
      "[5 rows x 1947 columns]\n",
      "df_sample_submission:                               id  F1  F2  F3  F4  F5  F6  F7  F8  F9  F10  \\\n",
      "0  HOBBIES_1_001_CA_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
      "1  HOBBIES_1_002_CA_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
      "2  HOBBIES_1_003_CA_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
      "3  HOBBIES_1_004_CA_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
      "4  HOBBIES_1_005_CA_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
      "\n",
      "   F11  F12  F13  F14  F15  F16  F17  F18  F19  F20  F21  F22  F23  F24  F25  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "\n",
      "   F26  F27  F28  \n",
      "0    0    0    0  \n",
      "1    0    0    0  \n",
      "2    0    0    0  \n",
      "3    0    0    0  \n",
      "4    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "print(f\"df_sales_train_evaluation: {df_sales_train_evaluation.head()}\")\n",
    "print(f\"df_sample_submission: {df_sample_submission.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constant variables for preprocessing/prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_NUM_UNIQUE_ITEM_ID: 30490\n",
      "_DAYS_FOR_PREDICTION: 28\n",
      "_SALES_HISTORY_START_DAYS_FOR_EVALUATION: 1942\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 予測期間とitem数の定義 / number of items, and number of prediction period\n",
    "_NUM_UNIQUE_ITEM_ID = df_sales_train_evaluation.shape[0]  # 30490\n",
    "print(f\"_NUM_UNIQUE_ITEM_ID: {_NUM_UNIQUE_ITEM_ID}\")\n",
    "_DAYS_FOR_PREDICTION = df_sample_submission.shape[1] - 1  # 28\n",
    "print(f\"_DAYS_FOR_PREDICTION: {_DAYS_FOR_PREDICTION}\")\n",
    "\n",
    "# DAYS_PER_YEAR = 365\n",
    "# _NUM_YEARS_FOR_MELT = 2\n",
    "# _NUM_IMPORT_ROWS_FOR_MELT = DAYS_PER_YEAR * _NUM_YEARS_FOR_MELT * _NUM_UNIQUE_ITEM_ID\n",
    "# print(f\"_NUM_IMPORT_ROWS_FOR_MELT: {_NUM_IMPORT_ROWS_FOR_MELT}\")\n",
    "\n",
    "_SALES_HISTORY_DAYS = 1913\n",
    "_SALES_HISTORY_START_DAYS_FOR_VALIDATION = _SALES_HISTORY_DAYS + 1\n",
    "_SALES_HISTORY_START_DAYS_FOR_EVALUATION = _SALES_HISTORY_START_DAYS_FOR_VALIDATION + _DAYS_FOR_PREDICTION\n",
    "print(f\"_SALES_HISTORY_START_DAYS_FOR_EVALUATION: {_SALES_HISTORY_START_DAYS_FOR_EVALUATION}\")\n",
    "\n",
    "TARGET = 'sales'\n",
    "MAIN_INDEX = ['id','d']  # We can identify items by these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Grid from df_sales_train_evaluation by melting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (30490, 1947), (59181090, 8)\n",
      "grid_df:                                      id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "59181085    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "59181086    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "59181087    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "59181088    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "59181089    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  \n",
      "0            CA_1       CA     d_1      0  \n",
      "1            CA_1       CA     d_1      0  \n",
      "2            CA_1       CA     d_1      0  \n",
      "3            CA_1       CA     d_1      0  \n",
      "4            CA_1       CA     d_1      0  \n",
      "...           ...      ...     ...    ...  \n",
      "59181085     WI_3       WI  d_1941      1  \n",
      "59181086     WI_3       WI  d_1941      0  \n",
      "59181087     WI_3       WI  d_1941      2  \n",
      "59181088     WI_3       WI  d_1941      0  \n",
      "59181089     WI_3       WI  d_1941      1  \n",
      "\n",
      "[59181090 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# We can tranform horizontal representation to vertical \"view\"\n",
    "# Our \"index\" will be 'id','item_id','dept_id','cat_id','store_id','state_id' and labels are 'd_' coulmns\n",
    "index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "\n",
    "grid_df = pd.melt(df_sales_train_evaluation, \n",
    "                  id_vars = index_columns, \n",
    "                  var_name = 'd', \n",
    "                  value_name = TARGET)\n",
    "\n",
    "print(f\"Train shapes: {df_sales_train_evaluation.shape}, {grid_df.shape}\")\n",
    "\n",
    "print(f\"grid_df: {grid_df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テスト結果を格納するためのRowを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test_result_receiver:                                   id        item_id    dept_id   cat_id  \\\n",
      "0      HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "1      HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
      "2      HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
      "3      HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
      "4      HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
      "...                              ...            ...        ...      ...   \n",
      "30485    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "30486    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "30487    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "30488    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "30489    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "      store_id state_id       d  sales  \n",
      "0         CA_1       CA  d_1942    NaN  \n",
      "1         CA_1       CA  d_1942    NaN  \n",
      "2         CA_1       CA  d_1942    NaN  \n",
      "3         CA_1       CA  d_1942    NaN  \n",
      "4         CA_1       CA  d_1942    NaN  \n",
      "...        ...      ...     ...    ...  \n",
      "30485     WI_3       WI  d_1969    NaN  \n",
      "30486     WI_3       WI  d_1969    NaN  \n",
      "30487     WI_3       WI  d_1969    NaN  \n",
      "30488     WI_3       WI  d_1969    NaN  \n",
      "30489     WI_3       WI  d_1969    NaN  \n",
      "\n",
      "[853720 rows x 8 columns]\n",
      "grid_df concatenated with df_test_result_receiver:                                      id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "60034805    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "60034806    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "60034807    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "60034808    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "60034809    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  \n",
      "0            CA_1       CA     d_1    0.0  \n",
      "1            CA_1       CA     d_1    0.0  \n",
      "2            CA_1       CA     d_1    0.0  \n",
      "3            CA_1       CA     d_1    0.0  \n",
      "4            CA_1       CA     d_1    0.0  \n",
      "...           ...      ...     ...    ...  \n",
      "60034805     WI_3       WI  d_1969    NaN  \n",
      "60034806     WI_3       WI  d_1969    NaN  \n",
      "60034807     WI_3       WI  d_1969    NaN  \n",
      "60034808     WI_3       WI  d_1969    NaN  \n",
      "60034809     WI_3       WI  d_1969    NaN  \n",
      "\n",
      "[60034810 rows x 8 columns]\n",
      "    Original grid_df:   3.6GiB\n",
      "grid_df[col]: 0           HOBBIES_1_001_CA_1_evaluation\n",
      "1           HOBBIES_1_002_CA_1_evaluation\n",
      "2           HOBBIES_1_003_CA_1_evaluation\n",
      "3           HOBBIES_1_004_CA_1_evaluation\n",
      "4           HOBBIES_1_005_CA_1_evaluation\n",
      "                        ...              \n",
      "60034805      FOODS_3_823_WI_3_evaluation\n",
      "60034806      FOODS_3_824_WI_3_evaluation\n",
      "60034807      FOODS_3_825_WI_3_evaluation\n",
      "60034808      FOODS_3_826_WI_3_evaluation\n",
      "60034809      FOODS_3_827_WI_3_evaluation\n",
      "Name: id, Length: 60034810, dtype: object\n",
      "grid_df[col]: 0           HOBBIES_1_001\n",
      "1           HOBBIES_1_002\n",
      "2           HOBBIES_1_003\n",
      "3           HOBBIES_1_004\n",
      "4           HOBBIES_1_005\n",
      "                ...      \n",
      "60034805      FOODS_3_823\n",
      "60034806      FOODS_3_824\n",
      "60034807      FOODS_3_825\n",
      "60034808      FOODS_3_826\n",
      "60034809      FOODS_3_827\n",
      "Name: item_id, Length: 60034810, dtype: object\n",
      "grid_df[col]: 0           HOBBIES_1\n",
      "1           HOBBIES_1\n",
      "2           HOBBIES_1\n",
      "3           HOBBIES_1\n",
      "4           HOBBIES_1\n",
      "              ...    \n",
      "60034805      FOODS_3\n",
      "60034806      FOODS_3\n",
      "60034807      FOODS_3\n",
      "60034808      FOODS_3\n",
      "60034809      FOODS_3\n",
      "Name: dept_id, Length: 60034810, dtype: object\n",
      "grid_df[col]: 0           HOBBIES\n",
      "1           HOBBIES\n",
      "2           HOBBIES\n",
      "3           HOBBIES\n",
      "4           HOBBIES\n",
      "             ...   \n",
      "60034805      FOODS\n",
      "60034806      FOODS\n",
      "60034807      FOODS\n",
      "60034808      FOODS\n",
      "60034809      FOODS\n",
      "Name: cat_id, Length: 60034810, dtype: object\n",
      "grid_df[col]: 0           CA_1\n",
      "1           CA_1\n",
      "2           CA_1\n",
      "3           CA_1\n",
      "4           CA_1\n",
      "            ... \n",
      "60034805    WI_3\n",
      "60034806    WI_3\n",
      "60034807    WI_3\n",
      "60034808    WI_3\n",
      "60034809    WI_3\n",
      "Name: store_id, Length: 60034810, dtype: object\n",
      "grid_df[col]: 0           CA\n",
      "1           CA\n",
      "2           CA\n",
      "3           CA\n",
      "4           CA\n",
      "            ..\n",
      "60034805    WI\n",
      "60034806    WI\n",
      "60034807    WI\n",
      "60034808    WI\n",
      "60034809    WI\n",
      "Name: state_id, Length: 60034810, dtype: object\n",
      "     Reduced grid_df:   1.3GiB\n"
     ]
    }
   ],
   "source": [
    "# add the test result receiver column to grid_df\n",
    "df_test_result_receiver = pd.DataFrame()\n",
    "for i in range(0,_DAYS_FOR_PREDICTION):\n",
    "    temp_df = df_sales_train_evaluation[index_columns]\n",
    "    temp_df = temp_df.drop_duplicates() # snince \"id\" is unique, this is not necessary\n",
    "    temp_df['d'] = 'd_'+ str(_SALES_HISTORY_START_DAYS_FOR_EVALUATION + i)\n",
    "    temp_df[TARGET] = np.nan\n",
    "    df_test_result_receiver = pd.concat([df_test_result_receiver,temp_df])\n",
    "\n",
    "print(f\"df_test_result_receiver: {df_test_result_receiver}\")\n",
    "\n",
    "grid_df = pd.concat([grid_df, df_test_result_receiver])\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"grid_df concatenated with df_test_result_receiver: {grid_df}\")\n",
    "\n",
    "# 一時的なDFを削除する\n",
    "# We will not need original train_df anymore and can remove it\n",
    "del temp_df, df_test_result_receiver\n",
    "# del temp_df, df_test_result_receiver, df_sales_train_evaluation\n",
    "gc.collect()\n",
    "\n",
    "# check memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# change the data type from string into category for memory reduction\n",
    "for col in index_columns:\n",
    "    print(f\"grid_df[col]: {grid_df[col]}\")\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# check memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove some 0 sale price rows which actually means that products do not exist yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_release_week_df:       store_id          item_id  release\n",
      "0         CA_1      FOODS_1_001    11101\n",
      "1         CA_1      FOODS_1_002    11101\n",
      "2         CA_1      FOODS_1_003    11101\n",
      "3         CA_1      FOODS_1_004    11206\n",
      "4         CA_1      FOODS_1_005    11101\n",
      "...        ...              ...      ...\n",
      "30485     WI_3  HOUSEHOLD_2_512    11101\n",
      "30486     WI_3  HOUSEHOLD_2_513    11311\n",
      "30487     WI_3  HOUSEHOLD_2_514    11101\n",
      "30488     WI_3  HOUSEHOLD_2_515    11352\n",
      "30489     WI_3  HOUSEHOLD_2_516    11101\n",
      "\n",
      "[30490 rows x 3 columns]\n",
      "grid_df after concatenating with item_release_week_df:                                      id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "60034805    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "60034806    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "60034807    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "60034808    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "60034809    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  release  \n",
      "0            CA_1       CA     d_1    0.0    11325  \n",
      "1            CA_1       CA     d_1    0.0    11121  \n",
      "2            CA_1       CA     d_1    0.0    11401  \n",
      "3            CA_1       CA     d_1    0.0    11106  \n",
      "4            CA_1       CA     d_1    0.0    11117  \n",
      "...           ...      ...     ...    ...      ...  \n",
      "60034805     WI_3       WI  d_1969    NaN    11101  \n",
      "60034806     WI_3       WI  d_1969    NaN    11101  \n",
      "60034807     WI_3       WI  d_1969    NaN    11101  \n",
      "60034808     WI_3       WI  d_1969    NaN    11331  \n",
      "60034809     WI_3       WI  d_1969    NaN    11405  \n",
      "\n",
      "[60034810 rows x 9 columns]\n",
      "grid_df after concatenating with df_calendar:                                      id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "60034805    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "60034806    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "60034807    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "60034808    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "60034809    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  release  wm_yr_wk  \n",
      "0            CA_1       CA     d_1    0.0    11325     11101  \n",
      "1            CA_1       CA     d_1    0.0    11121     11101  \n",
      "2            CA_1       CA     d_1    0.0    11401     11101  \n",
      "3            CA_1       CA     d_1    0.0    11106     11101  \n",
      "4            CA_1       CA     d_1    0.0    11117     11101  \n",
      "...           ...      ...     ...    ...      ...       ...  \n",
      "60034805     WI_3       WI  d_1969    NaN    11101     11621  \n",
      "60034806     WI_3       WI  d_1969    NaN    11101     11621  \n",
      "60034807     WI_3       WI  d_1969    NaN    11101     11621  \n",
      "60034808     WI_3       WI  d_1969    NaN    11331     11621  \n",
      "60034809     WI_3       WI  d_1969    NaN    11405     11621  \n",
      "\n",
      "[60034810 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 各train_dfアイテム行の先行ゼロ値は実際の0売上ではなく、店にアイテムがないことを意味する。\n",
    "# そのようなゼロを削除することで、一部のメモリを安全にする。\n",
    "\n",
    "# 価格は州ごとに設定されるので、 リリース週があまり正確ではありません\n",
    "# find the oldest release week (= smallest wm_yr_wk) of each item at each store\n",
    "item_release_week_df = df_sell_prices.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "# display(df_sell_prices.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']))\n",
    "# display(df_sell_prices.groupby(['store_id','item_id']).get_group((\"CA_1\", \"FOODS_1_001\")))\n",
    "# display(df_sell_prices.groupby(['store_id','item_id']).get_group((\"CA_1\", \"FOODS_1_001\")).agg(['min']))\n",
    "# display(df_sell_prices.groupby(['store_id','item_id'])['wm_yr_wk'].get_group((\"CA_1\", \"FOODS_1_001\")))\n",
    "\n",
    "# just change the column name from \"min\" to \"release\"\n",
    "item_release_week_df.columns = ['store_id','item_id','release']\n",
    "print(f\"item_release_week_df: {item_release_week_df}\")\n",
    "\n",
    "# concat with grid_d\n",
    "grid_df = merge_by_concat(grid_df, item_release_week_df, ['store_id','item_id'])\n",
    "del item_release_week_df\n",
    "gc.collect()\n",
    "print(f\"grid_df after concatenating with item_release_week_df: {grid_df}\")\n",
    "\n",
    "# grid_dfから「ゼロ」行をいくつか削除したい  \n",
    "# それを行うには、wm_yr_wk列が必要\n",
    "# 部分的にcalendar_dfを結合\n",
    "grid_df = merge_by_concat(grid_df, df_calendar[['wm_yr_wk','d']], ['d'])\n",
    "print(f\"grid_df after concatenating with df_calendar: {grid_df}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Original grid_df:   1.2GiB\n",
      "grid_df after removing uneccesary rows:                                      id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_008_CA_1_evaluation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_009_CA_1_evaluation  HOBBIES_1_009  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_010_CA_1_evaluation  HOBBIES_1_010  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_012_CA_1_evaluation  HOBBIES_1_012  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_015_CA_1_evaluation  HOBBIES_1_015  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "47735392    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "47735393    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "47735394    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "47735395    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "47735396    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  release  wm_yr_wk  \n",
      "0            CA_1       CA     d_1   12.0    11101     11101  \n",
      "1            CA_1       CA     d_1    2.0    11101     11101  \n",
      "2            CA_1       CA     d_1    0.0    11101     11101  \n",
      "3            CA_1       CA     d_1    0.0    11101     11101  \n",
      "4            CA_1       CA     d_1    4.0    11101     11101  \n",
      "...           ...      ...     ...    ...      ...       ...  \n",
      "47735392     WI_3       WI  d_1969    NaN    11101     11621  \n",
      "47735393     WI_3       WI  d_1969    NaN    11101     11621  \n",
      "47735394     WI_3       WI  d_1969    NaN    11101     11621  \n",
      "47735395     WI_3       WI  d_1969    NaN    11331     11621  \n",
      "47735396     WI_3       WI  d_1969    NaN    11405     11621  \n",
      "\n",
      "[47735397 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# これで、いくつかの行をカットして安全なメモリにできます\n",
    "# remove the rows whose release week is earlier than 'wm_yr_wk' when products should not be started  to be sold.\n",
    "grid_df = grid_df[grid_df['wm_yr_wk'] >= grid_df['release']]\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# メモリ使用量を確認しましょう\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "print(f\"grid_df after removing uneccesary rows: {grid_df}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Reduced grid_df:   1.2GiB\n",
      "grid_df:                                     id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_008_CA_1_evaluation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_009_CA_1_evaluation  HOBBIES_1_009  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_010_CA_1_evaluation  HOBBIES_1_010  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_012_CA_1_evaluation  HOBBIES_1_012  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_015_CA_1_evaluation  HOBBIES_1_015  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "47735392    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "47735393    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "47735394    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "47735395    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "47735396    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  release  wm_yr_wk  \n",
      "0            CA_1       CA     d_1   12.0        0     11101  \n",
      "1            CA_1       CA     d_1    2.0        0     11101  \n",
      "2            CA_1       CA     d_1    0.0        0     11101  \n",
      "3            CA_1       CA     d_1    0.0        0     11101  \n",
      "4            CA_1       CA     d_1    4.0        0     11101  \n",
      "...           ...      ...     ...    ...      ...       ...  \n",
      "47735392     WI_3       WI  d_1969    NaN        0     11621  \n",
      "47735393     WI_3       WI  d_1969    NaN        0     11621  \n",
      "47735394     WI_3       WI  d_1969    NaN        0     11621  \n",
      "47735395     WI_3       WI  d_1969    NaN      230     11621  \n",
      "47735396     WI_3       WI  d_1969    NaN      304     11621  \n",
      "\n",
      "[47735397 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 特徴量の1つとしてリリース週を維持する必要がありますか？ \n",
    "# 良いCVだけが答えを出すことができます。 \n",
    "# リリース値を縮小してみましょう。 \n",
    "# 最小変換はここでは役に立たない\n",
    "# int16→integer（-32768から32767） grid_df ['release'].max（）→int16のような変換は。\n",
    "# しかし、必要な場合に備えて、変換するある方法があります。\n",
    "grid_df['release'] = grid_df['release'] - grid_df['release'].min()\n",
    "grid_df['release'] = grid_df['release'].astype(np.int16)\n",
    "\n",
    "# メモリ使用量をもう一度確認してみましょう\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "print(f\"grid_df:{grid_df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export the base grid (grid_part_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data export start\n",
      "data export finished. Size: (47735397, 10)\n"
     ]
    }
   ],
   "source": [
    "# save the base grid file as pickle for later usage.\n",
    "_EXPORT_FILE_NAME = \"base_grid_for_darker_magic_evaluation.pkl\"\n",
    "print(\"data export start\")\n",
    "grid_df.to_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, _EXPORT_FILE_NAME]))\n",
    "\n",
    "print('data export finished. Size:', grid_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- you can split the notebook here -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing df_sell_prices: add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price\n",
       "0     CA_1  HOBBIES_1_001     11325    9.578125\n",
       "1     CA_1  HOBBIES_1_001     11326    9.578125\n",
       "2     CA_1  HOBBIES_1_001     11327    8.257812\n",
       "3     CA_1  HOBBIES_1_001     11328    8.257812\n",
       "4     CA_1  HOBBIES_1_001     11329    8.257812"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_sell_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sell_prices['price_max']: 0          9.578125\n",
      "1          9.578125\n",
      "2          9.578125\n",
      "3          9.578125\n",
      "4          9.578125\n",
      "             ...   \n",
      "6841116    1.000000\n",
      "6841117    1.000000\n",
      "6841118    1.000000\n",
      "6841119    1.000000\n",
      "6841120    1.000000\n",
      "Name: price_max, Length: 6841121, dtype: float16\n",
      "df_sell_prices['price_norm']: 0          1.000000\n",
      "1          1.000000\n",
      "2          0.862305\n",
      "3          0.862305\n",
      "4          0.862305\n",
      "             ...   \n",
      "6841116    1.000000\n",
      "6841117    1.000000\n",
      "6841118    1.000000\n",
      "6841119    1.000000\n",
      "6841120    1.000000\n",
      "Name: price_norm, Length: 6841121, dtype: float16\n",
      "df_sell_prices['price_norm'].shape: (6841121,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_norm</th>\n",
       "      <th>price_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price  price_max  price_min  \\\n",
       "0     CA_1  HOBBIES_1_001     11325    9.578125   9.578125   8.257812   \n",
       "1     CA_1  HOBBIES_1_001     11326    9.578125   9.578125   8.257812   \n",
       "2     CA_1  HOBBIES_1_001     11327    8.257812   9.578125   8.257812   \n",
       "3     CA_1  HOBBIES_1_001     11328    8.257812   9.578125   8.257812   \n",
       "4     CA_1  HOBBIES_1_001     11329    8.257812   9.578125   8.257812   \n",
       "\n",
       "   price_std  price_mean  price_norm  price_nunique  item_nunique  month  year  \n",
       "0   0.152344     8.28125    1.000000            3.0             3      7  2013  \n",
       "1   0.152344     8.28125    1.000000            3.0             3      7  2013  \n",
       "2   0.152344     8.28125    0.862305            3.0             5      7  2013  \n",
       "3   0.152344     8.28125    0.862305            3.0             5      8  2013  \n",
       "4   0.152344     8.28125    0.862305            3.0             5      8  2013  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 基本的な集計を行う\n",
    "# the max, min, std, mean price among the same item at the same store\n",
    "df_sell_prices['price_max'] = df_sell_prices.groupby(['store_id','item_id'])['sell_price'].transform('max')\n",
    "df_sell_prices['price_min'] = df_sell_prices.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "df_sell_prices['price_std'] = df_sell_prices.groupby(['store_id','item_id'])['sell_price'].transform('std')\n",
    "df_sell_prices['price_mean'] = df_sell_prices.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n",
    "\n",
    "print(f\"df_sell_prices['price_max']: {df_sell_prices['price_max']}\")\n",
    "# 価格正規化を行う（min-max scaling）。priceのレンジは大きくないので、Logを行う意味なし。（むしろ、一ドル以下の商品が多いので悪い）\n",
    "df_sell_prices['price_norm'] = df_sell_prices['sell_price']/df_sell_prices['price_max']\n",
    "print(f\"df_sell_prices['price_norm']: {df_sell_prices['price_norm']}\")\n",
    "print(f\"df_sell_prices['price_norm'].shape: {df_sell_prices['price_norm'].shape}\")\n",
    "\n",
    "# # since the price distribution is not very skewed or long-tailed, I decided not to take log scale. see: https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda\n",
    "# df_sell_prices['price_norm'] = np.log1p(df_sell_prices['sell_price'])\n",
    "# print(f\"log1p df_sell_prices['price_norm']: {df_sell_prices['price_norm']}\")\n",
    "# print(f\"log1p df_sell_prices['price_norm'].shape: {df_sell_prices['price_norm'].shape}\")\n",
    "\n",
    "# since \"pt.fit(sell_price_2d_array)\" caused \"ValueError: Input contains infinity or a value too large for dtype('float16').\", box-cox transformation was discarded: from scipy import stats also did not make propcer transform.\n",
    "# # https://note.com/mikiokubo/n/n42417e5d0f6c\n",
    "# # https://gakushukun1.hatenablog.com/entry/2019/04/29/112424\n",
    "# pt = PowerTransformer(method=\"box-cox\")\n",
    "# sell_price_2d_array = df_sell_prices['sell_price'].values.reshape(-1,1)\n",
    "# # data = df[\"B\"].values\n",
    "# print(f\"sell_price_2d_array: {sell_price_2d_array}\")\n",
    "# pt.fit(sell_price_2d_array)\n",
    "# df_sell_prices['price_norm'] = pt.transform(sell_price_2d_array)\n",
    "# df_sell_prices['price_norm'].hist()\n",
    "# print(f\"box-coxed df_sell_prices['price_norm']: {df_sell_prices['price_norm']}\")\n",
    "# print(f\"box-coxed df_sell_prices['price_norm'].shape: {df_sell_prices['price_norm'].shape}\")\n",
    "\n",
    "# 一部のアイテムはインフレに依存する可能性があります。いくつかのアイテムは非常に「安定」しています\n",
    "# count the kinds of sell_price per ['store_id','item_id']. the smaller, the more stable the price is.\n",
    "df_sell_prices['price_nunique'] = df_sell_prices.groupby(['store_id','item_id'])['sell_price'].transform('nunique')\n",
    "# count the kinds of item_id per ['store_id','sell_price']. the smaller, the less frequent the price is, whether the price is large or small. todo@kensakuokada: this feature may not be necessary.\n",
    "df_sell_prices['item_nunique'] = df_sell_prices.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n",
    "\n",
    "# I would like some \"rolling\" aggregations but would like months and years as \"window\"\n",
    "calendar_prices = df_calendar[['wm_yr_wk','month','year']]\n",
    "# the rows are duplicated in each week. reduce rows per week\n",
    "calendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk'])\n",
    "# add month and year\n",
    "df_sell_prices = df_sell_prices.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')\n",
    "\n",
    "del calendar_prices\n",
    "gc.collect()\n",
    "\n",
    "display(df_sell_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_norm</th>\n",
       "      <th>price_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>price_momentum</th>\n",
       "      <th>price_momentum_m</th>\n",
       "      <th>price_momentum_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.126953</td>\n",
       "      <td>1.144531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.126953</td>\n",
       "      <td>1.144531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>0.971680</td>\n",
       "      <td>0.986816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>9.578125</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>8.28125</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price  price_max  price_min  \\\n",
       "0     CA_1  HOBBIES_1_001     11325    9.578125   9.578125   8.257812   \n",
       "1     CA_1  HOBBIES_1_001     11326    9.578125   9.578125   8.257812   \n",
       "2     CA_1  HOBBIES_1_001     11327    8.257812   9.578125   8.257812   \n",
       "3     CA_1  HOBBIES_1_001     11328    8.257812   9.578125   8.257812   \n",
       "4     CA_1  HOBBIES_1_001     11329    8.257812   9.578125   8.257812   \n",
       "\n",
       "   price_std  price_mean  price_norm  price_nunique  item_nunique  \\\n",
       "0   0.152344     8.28125    1.000000            3.0             3   \n",
       "1   0.152344     8.28125    1.000000            3.0             3   \n",
       "2   0.152344     8.28125    0.862305            3.0             5   \n",
       "3   0.152344     8.28125    0.862305            3.0             5   \n",
       "4   0.152344     8.28125    0.862305            3.0             5   \n",
       "\n",
       "   price_momentum  price_momentum_m  price_momentum_y  \n",
       "0             NaN          1.126953          1.144531  \n",
       "1        1.000000          1.126953          1.144531  \n",
       "2        0.862305          0.971680          0.986816  \n",
       "3        1.000000          1.000000          0.986816  \n",
       "4        1.000000          1.000000          0.986816  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 週ごとにシフト in each (['store_id','item_id']) group. todo@kensakuokada: add more momentum by shifting more, which may be better.\n",
    "df_sell_prices['price_momentum'] = df_sell_prices['sell_price']/df_sell_prices.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "#  each sell price/月平均 in ['store_id','item_id','month'] group\n",
    "df_sell_prices['price_momentum_m'] = df_sell_prices['sell_price']/df_sell_prices.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "# each sell price/年平均 in ['store_id','item_id','year'] group\n",
    "df_sell_prices['price_momentum_y'] = df_sell_prices['sell_price']/df_sell_prices.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n",
    "\n",
    "del df_sell_prices['month'], df_sell_prices['year'] # todo@kensakuokada: try not to remove month and year, which may be better.\n",
    "gc.collect()\n",
    "\n",
    "display(df_sell_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing df_sell_prices: concat df_sell_prices with MAIN_INDEX (connecting with other dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_columns: ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd', 'sales', 'release', 'wm_yr_wk']\n",
      "grid_df:                                      id        item_id    dept_id   cat_id  \\\n",
      "0         HOBBIES_1_008_CA_1_evaluation  HOBBIES_1_008  HOBBIES_1  HOBBIES   \n",
      "1         HOBBIES_1_009_CA_1_evaluation  HOBBIES_1_009  HOBBIES_1  HOBBIES   \n",
      "2         HOBBIES_1_010_CA_1_evaluation  HOBBIES_1_010  HOBBIES_1  HOBBIES   \n",
      "3         HOBBIES_1_012_CA_1_evaluation  HOBBIES_1_012  HOBBIES_1  HOBBIES   \n",
      "4         HOBBIES_1_015_CA_1_evaluation  HOBBIES_1_015  HOBBIES_1  HOBBIES   \n",
      "...                                 ...            ...        ...      ...   \n",
      "47735392    FOODS_3_823_WI_3_evaluation    FOODS_3_823    FOODS_3    FOODS   \n",
      "47735393    FOODS_3_824_WI_3_evaluation    FOODS_3_824    FOODS_3    FOODS   \n",
      "47735394    FOODS_3_825_WI_3_evaluation    FOODS_3_825    FOODS_3    FOODS   \n",
      "47735395    FOODS_3_826_WI_3_evaluation    FOODS_3_826    FOODS_3    FOODS   \n",
      "47735396    FOODS_3_827_WI_3_evaluation    FOODS_3_827    FOODS_3    FOODS   \n",
      "\n",
      "         store_id state_id       d  sales  release  wm_yr_wk  sell_price  \\\n",
      "0            CA_1       CA     d_1   12.0        0     11101    0.459961   \n",
      "1            CA_1       CA     d_1    2.0        0     11101    1.559570   \n",
      "2            CA_1       CA     d_1    0.0        0     11101    3.169922   \n",
      "3            CA_1       CA     d_1    0.0        0     11101    5.980469   \n",
      "4            CA_1       CA     d_1    4.0        0     11101    0.700195   \n",
      "...           ...      ...     ...    ...      ...       ...         ...   \n",
      "47735392     WI_3       WI  d_1969    NaN        0     11621    2.980469   \n",
      "47735393     WI_3       WI  d_1969    NaN        0     11621    2.480469   \n",
      "47735394     WI_3       WI  d_1969    NaN        0     11621    3.980469   \n",
      "47735395     WI_3       WI  d_1969    NaN      230     11621    1.280273   \n",
      "47735396     WI_3       WI  d_1969    NaN      304     11621    1.000000   \n",
      "\n",
      "          price_max  price_min  price_std  price_mean  price_norm  \\\n",
      "0          0.500000   0.419922   0.019791    0.476318    0.919922   \n",
      "1          1.769531   1.559570   0.032715    1.764648    0.881348   \n",
      "2          3.169922   2.970703   0.046173    2.982422    1.000000   \n",
      "3          6.519531   5.980469   0.115906    6.468750    0.917480   \n",
      "4          0.720215   0.680176   0.011353    0.707031    0.972168   \n",
      "...             ...        ...        ...         ...         ...   \n",
      "47735392   2.980469   2.480469   0.171875    2.802734    1.000000   \n",
      "47735393   2.679688   2.000000   0.252930    2.507812    0.925781   \n",
      "47735394   4.378906   3.980469   0.187866    4.117188    0.909180   \n",
      "47735395   1.280273   1.280273   0.000000    1.280273    1.000000   \n",
      "47735396   1.000000   1.000000   0.000000    1.000000    1.000000   \n",
      "\n",
      "          price_nunique  item_nunique  price_momentum  price_momentum_m  \\\n",
      "0                   4.0            16             NaN          0.968750   \n",
      "1                   2.0             9             NaN          0.885742   \n",
      "2                   2.0            20             NaN          1.064453   \n",
      "3                   3.0            71             NaN          0.922363   \n",
      "4                   3.0            16             NaN          0.990234   \n",
      "...                 ...           ...             ...               ...   \n",
      "47735392            5.0           206             1.0          1.032227   \n",
      "47735393            4.0           135             1.0          0.985840   \n",
      "47735394            3.0           150             1.0          0.957520   \n",
      "47735395            1.0            44             1.0          1.000000   \n",
      "47735396            1.0           142             1.0          1.000000   \n",
      "\n",
      "          price_momentum_y  \n",
      "0                 0.949707  \n",
      "1                 0.896484  \n",
      "2                 1.043945  \n",
      "3                 0.959473  \n",
      "4                 1.001953  \n",
      "...                    ...  \n",
      "47735392          1.022461  \n",
      "47735393          1.112305  \n",
      "47735394          1.000000  \n",
      "47735395          1.000000  \n",
      "47735396          1.000000  \n",
      "\n",
      "[47735397 rows x 21 columns]\n",
      "keep_columns: ['sell_price', 'price_max', 'price_min', 'price_std', 'price_mean', 'price_norm', 'price_nunique', 'item_nunique', 'price_momentum', 'price_momentum_m', 'price_momentum_y']\n",
      "Mem. usage decreased to 1822.44 Mb (13.0% reduction)\n",
      "grid_df:                                      id       d  sell_price  price_max  \\\n",
      "0         HOBBIES_1_008_CA_1_evaluation     d_1    0.459961   0.500000   \n",
      "1         HOBBIES_1_009_CA_1_evaluation     d_1    1.559570   1.769531   \n",
      "2         HOBBIES_1_010_CA_1_evaluation     d_1    3.169922   3.169922   \n",
      "3         HOBBIES_1_012_CA_1_evaluation     d_1    5.980469   6.519531   \n",
      "4         HOBBIES_1_015_CA_1_evaluation     d_1    0.700195   0.720215   \n",
      "...                                 ...     ...         ...        ...   \n",
      "47735392    FOODS_3_823_WI_3_evaluation  d_1969    2.980469   2.980469   \n",
      "47735393    FOODS_3_824_WI_3_evaluation  d_1969    2.480469   2.679688   \n",
      "47735394    FOODS_3_825_WI_3_evaluation  d_1969    3.980469   4.378906   \n",
      "47735395    FOODS_3_826_WI_3_evaluation  d_1969    1.280273   1.280273   \n",
      "47735396    FOODS_3_827_WI_3_evaluation  d_1969    1.000000   1.000000   \n",
      "\n",
      "          price_min  price_std  price_mean  price_norm  price_nunique  \\\n",
      "0          0.419922   0.019791    0.476318    0.919922            4.0   \n",
      "1          1.559570   0.032715    1.764648    0.881348            2.0   \n",
      "2          2.970703   0.046173    2.982422    1.000000            2.0   \n",
      "3          5.980469   0.115906    6.468750    0.917480            3.0   \n",
      "4          0.680176   0.011353    0.707031    0.972168            3.0   \n",
      "...             ...        ...         ...         ...            ...   \n",
      "47735392   2.480469   0.171875    2.802734    1.000000            5.0   \n",
      "47735393   2.000000   0.252930    2.507812    0.925781            4.0   \n",
      "47735394   3.980469   0.187866    4.117188    0.909180            3.0   \n",
      "47735395   1.280273   0.000000    1.280273    1.000000            1.0   \n",
      "47735396   1.000000   0.000000    1.000000    1.000000            1.0   \n",
      "\n",
      "          item_nunique  price_momentum  price_momentum_m  price_momentum_y  \n",
      "0                   16             NaN          0.968750          0.949707  \n",
      "1                    9             NaN          0.885742          0.896484  \n",
      "2                   20             NaN          1.064453          1.043945  \n",
      "3                   71             NaN          0.922363          0.959473  \n",
      "4                   16             NaN          0.990234          1.001953  \n",
      "...                ...             ...               ...               ...  \n",
      "47735392           206             1.0          1.032227          1.022461  \n",
      "47735393           135             1.0          0.985840          1.112305  \n",
      "47735394           150             1.0          0.957520          1.000000  \n",
      "47735395            44             1.0          1.000000          1.000000  \n",
      "47735396           142             1.0          1.000000          1.000000  \n",
      "\n",
      "[47735397 rows x 13 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base columns\n",
    "original_columns = list(grid_df)\n",
    "print(f\"original_columns: {original_columns}\")\n",
    "\n",
    "grid_df = grid_df.merge(df_sell_prices, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "print(f\"grid_df: {grid_df}\")\n",
    "\n",
    "keep_columns = [col for col in list(grid_df) if col not in original_columns]\n",
    "print(f\"keep_columns: {keep_columns}\")\n",
    "\n",
    "grid_df = grid_df[MAIN_INDEX+keep_columns]\n",
    "grid_df = reduce_mem_usage(grid_df)\n",
    "print(f\"grid_df: {grid_df}\")\n",
    "\n",
    "# We don't need prices_df anymore\n",
    "del df_sell_prices\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export grid_df having sales_price features and MAIN_INDEX (grid_part_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data export start\n",
      "data export finished. Size: (47735397, 13)\n"
     ]
    }
   ],
   "source": [
    "# 今後のモデルトレーニングのためpickleファイルとして保存\n",
    "_EXPORT_FILE_NAME = \"base_grid_with_sales_price_features_for_darker_magic_evaluation.pkl\"\n",
    "print(\"data export start\")\n",
    "grid_df.to_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, _EXPORT_FILE_NAME]))\n",
    "print('data export finished. Size:', grid_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- you can split the notebook here -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing df_calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_df:                                      id       d       date  event_name_1  \\\n",
      "0         HOBBIES_1_008_CA_1_evaluation     d_1 2011-01-29           NaN   \n",
      "1         HOBBIES_1_009_CA_1_evaluation     d_1 2011-01-29           NaN   \n",
      "2         HOBBIES_1_010_CA_1_evaluation     d_1 2011-01-29           NaN   \n",
      "3         HOBBIES_1_012_CA_1_evaluation     d_1 2011-01-29           NaN   \n",
      "4         HOBBIES_1_015_CA_1_evaluation     d_1 2011-01-29           NaN   \n",
      "...                                 ...     ...        ...           ...   \n",
      "47735392    FOODS_3_823_WI_3_evaluation  d_1969 2016-06-19  NBAFinalsEnd   \n",
      "47735393    FOODS_3_824_WI_3_evaluation  d_1969 2016-06-19  NBAFinalsEnd   \n",
      "47735394    FOODS_3_825_WI_3_evaluation  d_1969 2016-06-19  NBAFinalsEnd   \n",
      "47735395    FOODS_3_826_WI_3_evaluation  d_1969 2016-06-19  NBAFinalsEnd   \n",
      "47735396    FOODS_3_827_WI_3_evaluation  d_1969 2016-06-19  NBAFinalsEnd   \n",
      "\n",
      "         event_type_1  event_name_2 event_type_2 snap_CA snap_TX snap_WI  \\\n",
      "0                 NaN           NaN          NaN       0       0       0   \n",
      "1                 NaN           NaN          NaN       0       0       0   \n",
      "2                 NaN           NaN          NaN       0       0       0   \n",
      "3                 NaN           NaN          NaN       0       0       0   \n",
      "4                 NaN           NaN          NaN       0       0       0   \n",
      "...               ...           ...          ...     ...     ...     ...   \n",
      "47735392     Sporting  Father's day     Cultural       0       0       0   \n",
      "47735393     Sporting  Father's day     Cultural       0       0       0   \n",
      "47735394     Sporting  Father's day     Cultural       0       0       0   \n",
      "47735395     Sporting  Father's day     Cultural       0       0       0   \n",
      "47735396     Sporting  Father's day     Cultural       0       0       0   \n",
      "\n",
      "          tm_d  tm_w  tm_m  tm_y  tm_wm  tm_dw  tm_w_end  \n",
      "0           29     4     1     0      5      5         1  \n",
      "1           29     4     1     0      5      5         1  \n",
      "2           29     4     1     0      5      5         1  \n",
      "3           29     4     1     0      5      5         1  \n",
      "4           29     4     1     0      5      5         1  \n",
      "...        ...   ...   ...   ...    ...    ...       ...  \n",
      "47735392    19    24     6     5      3      6         1  \n",
      "47735393    19    24     6     5      3      6         1  \n",
      "47735394    19    24     6     5      3      6         1  \n",
      "47735395    19    24     6     5      3      6         1  \n",
      "47735396    19    24     6     5      3      6         1  \n",
      "\n",
      "[47735397 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "grid_df = grid_df[MAIN_INDEX]\n",
    "\n",
    "# カレンダーを部分的に結合\n",
    "icols = ['date',\n",
    "         'd',\n",
    "         'event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "\n",
    "grid_df = grid_df.merge(df_calendar[icols], on=['d'], how='left')\n",
    "\n",
    "# データを縮小する \n",
    "# 'snap_'列はboolまたはint8に変換できる \n",
    "icols = ['event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "for col in icols:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# 日時に変換\n",
    "grid_df['date'] = pd.to_datetime(grid_df['date'])\n",
    "\n",
    "# 日付からいくつかの特徴量を作る\n",
    "grid_df['tm_d'] = grid_df['date'].dt.day.astype(np.int8)\n",
    "grid_df['tm_w'] = grid_df['date'].dt.week.astype(np.int8)\n",
    "grid_df['tm_m'] = grid_df['date'].dt.month.astype(np.int8)\n",
    "grid_df['tm_y'] = grid_df['date'].dt.year\n",
    "grid_df['tm_y'] = (grid_df['tm_y'] - grid_df['tm_y'].min()).astype(np.int8)\n",
    "grid_df['tm_wm'] = grid_df['tm_d'].apply(lambda x: math.ceil(x/7)).astype(np.int8)\n",
    "\n",
    "grid_df['tm_dw'] = grid_df['date'].dt.dayofweek.astype(np.int8)\n",
    "grid_df['tm_w_end'] = (grid_df['tm_dw']>=5).astype(np.int8)\n",
    "\n",
    "print(f\"grid_df: {grid_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の削除\n",
    "del grid_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47735397 entries, 0 to 47735396\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Dtype   \n",
      "---  ------        -----   \n",
      " 0   id            category\n",
      " 1   d             object  \n",
      " 2   event_name_1  category\n",
      " 3   event_type_1  category\n",
      " 4   event_name_2  category\n",
      " 5   event_type_2  category\n",
      " 6   snap_CA       category\n",
      " 7   snap_TX       category\n",
      " 8   snap_WI       category\n",
      " 9   tm_d          int8    \n",
      " 10  tm_w          int8    \n",
      " 11  tm_m          int8    \n",
      " 12  tm_y          int8    \n",
      " 13  tm_wm         int8    \n",
      " 14  tm_dw         int8    \n",
      " 15  tm_w_end      int8    \n",
      "dtypes: category(8), int8(7), object(1)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export grid_df having sales_price features and MAIN_INDEX (grid_part_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data export start\n",
      "data export finished. Size: (47735397, 16)\n"
     ]
    }
   ],
   "source": [
    "_EXPORT_FILE_NAME = \"base_grid_with_calendar_features_for_darker_magic_evaluation.pkl\"\n",
    "print(\"data export start\")\n",
    "grid_df.to_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, _EXPORT_FILE_NAME]))\n",
    "print('data export finished. Size:', grid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
