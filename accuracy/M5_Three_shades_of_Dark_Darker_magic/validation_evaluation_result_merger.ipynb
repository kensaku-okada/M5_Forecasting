{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.kaggle.com/kyakovlev/m5-custom-features from https://www.kaggle.com/ejunichi/m5-three-shades-of-dark-darker-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import gc\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import psutil\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function fixing random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Sets seed to make all processes deterministic     # type: int\n",
    "    \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constant variables for helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CORES: 36\n"
     ]
    }
   ],
   "source": [
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "print(f\"N_CORES: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  constant variables for data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this var according to the dataset you refer to \n",
    "# path to the source's pickle files\n",
    "# _DATA_DIR = os.path.sep.join([\"data\", \"M5_Three_shades_of_Dark_Darker_magic\", \"sample\"])\n",
    "_DATA_DIR = os.path.sep.join([\"data\", \"M5_Three_shades_of_Dark_Darker_magic\"])\n",
    "_OUTPUT_DIR = os.path.sep.join([\"data\", \"M5_Three_shades_of_Dark_Darker_magic\"])\n",
    "\n",
    "_VALIDATION_RESULT = \"submission_v3_validation.csv\"\n",
    "_EVALUATION_RESULT = \"submission_v3_evaluation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function nicely diplaying a head of Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "def display(*dfs, head=True):\n",
    "    for df in dfs:\n",
    "        IPython.display.display(df.head() if head else df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function processing df in multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_df_in_multiprocess(func, t_split):\n",
    "    \"\"\"Process ds in Multiprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    print(f\"num_cores: {num_cores}\")\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"メモリ使用量を確認するためのシンプルな「メモリプロファイラ」\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    \"\"\"\n",
    "    dtypesを失わないための連結による結合\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1\n",
    "\n",
    "\n",
    "def get_base_test():\n",
    "    \"\"\"Recombines Test set after training\n",
    "    \n",
    "    \"\"\"\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORE_IDS:\n",
    "        test_pkl_path = os.path.sep.join([PRETRAINED_MODEL_DIR, 'test_dataset_'+store_id+'.pkl'])\n",
    "        temp_df = pd.read_pickle(test_pkl_path)\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n",
    "\n",
    "\n",
    "\n",
    "##### Helper to make dynamic rolling lags #####\n",
    "def make_lag(lag_day):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'sales_lag_'+str(lag_day)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(lag_day)).astype(np.float16)\n",
    "    return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "def make_lag_roll(lag_day):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    shift_day = lag_day[0]\n",
    "    roll_wind = lag_day[1]\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "    return lag_df[[col_name]]\n",
    "##### Helper to make dynamic rolling lags #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    reduce the memory usage of the given dataframe.\n",
    "    https://qiita.com/hiroyuki_kageyama/items/02865616811022f79754\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe\n",
    "        verbose: \n",
    "        \n",
    "    Returns:\n",
    "        df, whose memory usage is reduced.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns: #columns毎に処理\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def read_csv_data(directory, file_name):\n",
    "    print('Reading files...')\n",
    "    df = pd.read_csv(os.path.sep.join([str(directory), _DATA_DIR, file_name]))\n",
    "    df = reduce_mem_usage(df)\n",
    "    print('{} has {} rows and {} columns'.format(file_name, df.shape[0], df.shape[1]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data_by_store(store):\n",
    "#     # Read and contact basic feature\n",
    "#     df = pd.concat([pd.read_pickle(BASE),\n",
    "#                     pd.read_pickle(PRICE).iloc[:,2:],\n",
    "#                     pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "#                     axis=1)\n",
    "\n",
    "    # Read and contact basic feature\n",
    "    parent_dir = pathlib.Path(os.path.abspath(os.curdir)).parent.parent\n",
    "    df = pd.concat([pd.read_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, BASE])),\n",
    "                    pd.read_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, PRICE])).iloc[:,2:],\n",
    "                    pd.read_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, CALENDAR])).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "#     print(f\"df at read_data_by_store: {df}\")\n",
    "    \n",
    "    # Leave only relevant store\n",
    "    df = df[df['store_id']==store]\n",
    "\n",
    "    # With memory limits we have to read lags and mean encoding features separately and drop items that we don't need.\n",
    "    # As our Features Grids are aligned \n",
    "    # we can use index to keep only necessary rows\n",
    "    # Alignment is good for us as concat uses less memory than merge.\n",
    "    df2 = pd.read_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, MEAN_ENC]))[MEAN_STD_FEATURES]\n",
    "    df2 = df2[df2.index.isin(df.index)]\n",
    "    print(f\"MEAN_ENC: {MEAN_ENC}\")\n",
    "    \n",
    "    df3 = pd.read_pickle(os.path.sep.join([str(parent_dir), _DATA_DIR, LAGS])).iloc[:,3:]\n",
    "    df3 = df3[df3.index.isin(df.index)]\n",
    "    print(f\"LAGS: {LAGS}\")\n",
    "    \n",
    "    df = pd.concat([df, df2], axis=1)\n",
    "    del df2 # to not reach memory limit \n",
    "    \n",
    "    df = pd.concat([df, df3], axis=1)\n",
    "    del df3 # to not reach memory limit \n",
    "    \n",
    "    # Create features list\n",
    "    features = [col for col in list(df) if col not in REMOVE_FEATURES]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    # Skipping first n rows\n",
    "    df = df[df['d']>=START_DAY_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    return df, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_dir: /home/ec2-user/SageMaker\n",
      "Reading files...\n",
      "Mem. usage decreased to  3.72 Mb (72.4% reduction)\n",
      "submission_v3_validation.csv has 60980 rows and 29 columns\n",
      "Reading files...\n",
      "Mem. usage decreased to  3.72 Mb (72.4% reduction)\n",
      "submission_v3_evaluation.csv has 60980 rows and 29 columns\n"
     ]
    }
   ],
   "source": [
    "parent_dir = pathlib.Path(os.path.abspath(os.curdir)).parent.parent\n",
    "print(f\"parent_dir: {parent_dir}\")\n",
    "\n",
    "validation_df = read_csv_data(parent_dir, _VALIDATION_RESULT)\n",
    "evaluation_df = read_csv_data(parent_dir, _EVALUATION_RESULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  id        F1        F2        F3        F4  \\\n",
      "0      HOBBIES_1_001_CA_1_validation  0.669434  0.569824  0.683594  0.586426   \n",
      "1      HOBBIES_1_002_CA_1_validation  0.220703  0.188721  0.195312  0.207642   \n",
      "2      HOBBIES_1_003_CA_1_validation  0.292725  0.276855  0.284912  0.298584   \n",
      "3      HOBBIES_1_004_CA_1_validation  1.514648  1.352539  1.205078  1.211914   \n",
      "4      HOBBIES_1_005_CA_1_validation  0.935059  0.808105  0.900879  0.946777   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "60975    FOODS_3_823_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
      "60976    FOODS_3_824_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
      "60977    FOODS_3_825_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
      "60978    FOODS_3_826_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
      "60979    FOODS_3_827_WI_3_evaluation  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "             F5        F6        F7        F8        F9       F10       F11  \\\n",
      "0      0.684570  0.791016  0.849121  0.580078  0.626465  0.684570  0.639648   \n",
      "1      0.236572  0.299072  0.318359  0.185669  0.204712  0.165771  0.192749   \n",
      "2      0.356201  0.442871  0.458984  0.316650  0.299072  0.259277  0.285645   \n",
      "3      1.737305  2.580078  2.664062  1.417969  1.289062  1.100586  1.215820   \n",
      "4      1.112305  1.436523  1.603516  1.056641  0.937988  0.820801  0.843750   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60976  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60977  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60978  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60979  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            F12       F13       F14       F15       F16       F17       F18  \\\n",
      "0      0.696289  0.896973  0.671387  0.603027  0.604004  0.547852  0.559570   \n",
      "1      0.198242  0.224854  0.208862  0.164185  0.151611  0.146118  0.158691   \n",
      "2      0.350342  0.428467  0.334229  0.294189  0.287598  0.265625  0.298340   \n",
      "3      1.456055  2.662109  2.158203  1.590820  1.214844  1.303711  1.182617   \n",
      "4      0.893066  1.391602  0.967773  1.015625  0.869141  0.845703  0.822754   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60976  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60977  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60978  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60979  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            F19       F20       F21       F22       F23       F24       F25  \\\n",
      "0      0.655273  0.872070  0.803711  0.738770  0.685059  0.653809  0.694336   \n",
      "1      0.171997  0.195312  0.200195  0.144775  0.135864  0.210938  0.223877   \n",
      "2      0.391846  0.510254  0.497559  0.348389  0.312256  0.337646  0.343506   \n",
      "3      1.618164  2.089844  2.787109  1.651367  1.242188  1.198242  1.270508   \n",
      "4      1.034180  1.333984  1.371094  0.849609  0.726074  0.758789  0.802734   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60976  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60977  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60978  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "60979  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            F26       F27       F28  \n",
      "0      0.733887  1.021484  1.047852  \n",
      "1      0.237427  0.281250  0.283447  \n",
      "2      0.475586  0.545898  0.532227  \n",
      "3      1.735352  3.205078  3.226562  \n",
      "4      0.953613  1.390625  1.543945  \n",
      "...         ...       ...       ...  \n",
      "60975  0.000000  0.000000  0.000000  \n",
      "60976  0.000000  0.000000  0.000000  \n",
      "60977  0.000000  0.000000  0.000000  \n",
      "60978  0.000000  0.000000  0.000000  \n",
      "60979  0.000000  0.000000  0.000000  \n",
      "\n",
      "[60980 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  id        F1        F2        F3        F4  \\\n",
      "0      HOBBIES_1_001_CA_1_validation  0.000000  0.000000  0.000000  0.000000   \n",
      "1      HOBBIES_1_002_CA_1_validation  0.000000  0.000000  0.000000  0.000000   \n",
      "2      HOBBIES_1_003_CA_1_validation  0.000000  0.000000  0.000000  0.000000   \n",
      "3      HOBBIES_1_004_CA_1_validation  0.000000  0.000000  0.000000  0.000000   \n",
      "4      HOBBIES_1_005_CA_1_validation  0.000000  0.000000  0.000000  0.000000   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "60975    FOODS_3_823_WI_3_evaluation  0.352783  0.295654  0.300049  0.378418   \n",
      "60976    FOODS_3_824_WI_3_evaluation  0.204346  0.207520  0.217285  0.221436   \n",
      "60977    FOODS_3_825_WI_3_evaluation  0.667969  0.559082  0.593262  0.562988   \n",
      "60978    FOODS_3_826_WI_3_evaluation  0.920898  0.991211  0.862305  0.969727   \n",
      "60979    FOODS_3_827_WI_3_evaluation  1.707031  1.809570  1.599609  1.524414   \n",
      "\n",
      "             F5        F6        F7        F8        F9       F10       F11  \\\n",
      "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.525391  0.501465  0.452637  0.485840  0.454590  0.422363  0.501953   \n",
      "60976  0.223755  0.263916  0.250488  0.236450  0.244629  0.281738  0.421387   \n",
      "60977  0.618164  0.802246  0.840332  0.785156  0.586426  0.720703  1.035156   \n",
      "60978  1.151367  1.318359  1.248047  1.077148  0.989746  0.804688  1.180664   \n",
      "60979  1.791016  1.963867  1.927734  1.722656  1.729492  1.535156  1.734375   \n",
      "\n",
      "            F12       F13       F14       F15       F16       F17       F18  \\\n",
      "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.585938  0.553711  0.665527  0.556152  0.445312  0.500000  0.506348   \n",
      "60976  0.405762  0.360352  0.456299  0.392822  0.328369  0.308838  0.270996   \n",
      "60977  1.134766  0.899902  1.229492  0.990234  0.762695  1.060547  1.162109   \n",
      "60978  1.455078  1.262695  1.515625  1.159180  0.892578  1.131836  1.123047   \n",
      "60979  2.183594  2.185547  2.384766  1.926758  1.747070  1.901367  1.933594   \n",
      "\n",
      "            F19       F20       F21       F22       F23       F24       F25  \\\n",
      "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.545410  0.569824  0.757324  0.550781  0.554688  0.601074  0.446777   \n",
      "60976  0.210815  0.303711  0.302979  0.245728  0.279785  0.276123  0.219482   \n",
      "60977  0.905273  1.245117  1.291992  1.111328  1.114258  1.087891  0.698730   \n",
      "60978  0.971680  1.379883  1.435547  1.191406  1.662109  1.511719  1.166992   \n",
      "60979  1.964844  2.371094  2.105469  1.889648  2.134766  1.774414  1.828125   \n",
      "\n",
      "            F26       F27       F28  \n",
      "0      0.000000  0.000000  0.000000  \n",
      "1      0.000000  0.000000  0.000000  \n",
      "2      0.000000  0.000000  0.000000  \n",
      "3      0.000000  0.000000  0.000000  \n",
      "4      0.000000  0.000000  0.000000  \n",
      "...         ...       ...       ...  \n",
      "60975  0.487549  0.604004  0.627441  \n",
      "60976  0.188965  0.285400  0.237549  \n",
      "60977  0.831055  0.884277  0.926270  \n",
      "60978  1.275391  1.530273  1.353516  \n",
      "60979  2.263672  2.714844  2.820312  \n",
      "\n",
      "[60980 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_df:                                   id        F1        F2        F3        F4  \\\n",
      "0      HOBBIES_1_001_CA_1_validation  0.669434  0.569824  0.683594  0.586426   \n",
      "1      HOBBIES_1_002_CA_1_validation  0.220703  0.188721  0.195312  0.207642   \n",
      "2      HOBBIES_1_003_CA_1_validation  0.292725  0.276855  0.284912  0.298584   \n",
      "3      HOBBIES_1_004_CA_1_validation  1.514648  1.352539  1.205078  1.211914   \n",
      "4      HOBBIES_1_005_CA_1_validation  0.935059  0.808105  0.900879  0.946777   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "60975    FOODS_3_823_WI_3_evaluation  0.352783  0.295654  0.300049  0.378418   \n",
      "60976    FOODS_3_824_WI_3_evaluation  0.204346  0.207520  0.217285  0.221436   \n",
      "60977    FOODS_3_825_WI_3_evaluation  0.667969  0.559082  0.593262  0.562988   \n",
      "60978    FOODS_3_826_WI_3_evaluation  0.920898  0.991211  0.862305  0.969727   \n",
      "60979    FOODS_3_827_WI_3_evaluation  1.707031  1.809570  1.599609  1.524414   \n",
      "\n",
      "             F5        F6        F7        F8        F9       F10       F11  \\\n",
      "0      0.684570  0.791016  0.849121  0.580078  0.626465  0.684570  0.639648   \n",
      "1      0.236572  0.299072  0.318359  0.185669  0.204712  0.165771  0.192749   \n",
      "2      0.356201  0.442871  0.458984  0.316650  0.299072  0.259277  0.285645   \n",
      "3      1.737305  2.580078  2.664062  1.417969  1.289062  1.100586  1.215820   \n",
      "4      1.112305  1.436523  1.603516  1.056641  0.937988  0.820801  0.843750   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.525391  0.501465  0.452637  0.485840  0.454590  0.422363  0.501953   \n",
      "60976  0.223755  0.263916  0.250488  0.236450  0.244629  0.281738  0.421387   \n",
      "60977  0.618164  0.802246  0.840332  0.785156  0.586426  0.720703  1.035156   \n",
      "60978  1.151367  1.318359  1.248047  1.077148  0.989746  0.804688  1.180664   \n",
      "60979  1.791016  1.963867  1.927734  1.722656  1.729492  1.535156  1.734375   \n",
      "\n",
      "            F12       F13       F14       F15       F16       F17       F18  \\\n",
      "0      0.696289  0.896973  0.671387  0.603027  0.604004  0.547852  0.559570   \n",
      "1      0.198242  0.224854  0.208862  0.164185  0.151611  0.146118  0.158691   \n",
      "2      0.350342  0.428467  0.334229  0.294189  0.287598  0.265625  0.298340   \n",
      "3      1.456055  2.662109  2.158203  1.590820  1.214844  1.303711  1.182617   \n",
      "4      0.893066  1.391602  0.967773  1.015625  0.869141  0.845703  0.822754   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.585938  0.553711  0.665527  0.556152  0.445312  0.500000  0.506348   \n",
      "60976  0.405762  0.360352  0.456299  0.392822  0.328369  0.308838  0.270996   \n",
      "60977  1.134766  0.899902  1.229492  0.990234  0.762695  1.060547  1.162109   \n",
      "60978  1.455078  1.262695  1.515625  1.159180  0.892578  1.131836  1.123047   \n",
      "60979  2.183594  2.185547  2.384766  1.926758  1.747070  1.901367  1.933594   \n",
      "\n",
      "            F19       F20       F21       F22       F23       F24       F25  \\\n",
      "0      0.655273  0.872070  0.803711  0.738770  0.685059  0.653809  0.694336   \n",
      "1      0.171997  0.195312  0.200195  0.144775  0.135864  0.210938  0.223877   \n",
      "2      0.391846  0.510254  0.497559  0.348389  0.312256  0.337646  0.343506   \n",
      "3      1.618164  2.089844  2.787109  1.651367  1.242188  1.198242  1.270508   \n",
      "4      1.034180  1.333984  1.371094  0.849609  0.726074  0.758789  0.802734   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "60975  0.545410  0.569824  0.757324  0.550781  0.554688  0.601074  0.446777   \n",
      "60976  0.210815  0.303711  0.302979  0.245728  0.279785  0.276123  0.219482   \n",
      "60977  0.905273  1.245117  1.291992  1.111328  1.114258  1.087891  0.698730   \n",
      "60978  0.971680  1.379883  1.435547  1.191406  1.662109  1.511719  1.166992   \n",
      "60979  1.964844  2.371094  2.105469  1.889648  2.134766  1.774414  1.828125   \n",
      "\n",
      "            F26       F27       F28  \n",
      "0      0.733887  1.021484  1.047852  \n",
      "1      0.237427  0.281250  0.283447  \n",
      "2      0.475586  0.545898  0.532227  \n",
      "3      1.735352  3.205078  3.226562  \n",
      "4      0.953613  1.390625  1.543945  \n",
      "...         ...       ...       ...  \n",
      "60975  0.487549  0.604004  0.627441  \n",
      "60976  0.188965  0.285400  0.237549  \n",
      "60977  0.831055  0.884277  0.926270  \n",
      "60978  1.275391  1.530273  1.353516  \n",
      "60979  2.263672  2.714844  2.820312  \n",
      "\n",
      "[60980 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "evaluation_df[evaluation_df[\"id\"].str.contains(\"validation\")] = validation_df[validation_df[\"id\"].str.contains(\"validation\")]\n",
    "\n",
    "print(f\"evaluation_df: {evaluation_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export train/test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv data export start\n",
      "csv data export finished. Size: (60980, 29)\n"
     ]
    }
   ],
   "source": [
    "parent_dir = pathlib.Path(os.path.abspath(os.curdir)).parent.parent\n",
    "# Reading competition sample submission and merging our predictions\n",
    "\n",
    "_EXPORT_FILE_NAME = _EVALUATION_RESULT\n",
    "print(\"csv data export start\")\n",
    "evaluation_df.to_csv(os.path.sep.join([str(parent_dir), _OUTPUT_DIR, _EXPORT_FILE_NAME]), index=False)\n",
    "print('csv data export finished. Size:', evaluation_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
